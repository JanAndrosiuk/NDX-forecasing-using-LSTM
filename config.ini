[logger]
LoggerLevel = 20
TensorboardLoggerPath = reports/tblogs

[raw]
IcsaRawDF = data/raw/icsa.csv
CandleRawDF = data/raw/ndx.csv

[prep]
DataPreprocessedDir = data/preprocessed/
DataInputDir = data/input/
DataOutputDir = data/output/
ReportDir = reports/
VisualizationsDir = reports/figures/
FFilledIcsaDfPkl = data/preprocessed/icsa_ffilled.pkl
FFilledIcsaDfCsv = data/preprocessed/icsa_ffilled.csv
TisDfPkl = data/preprocessed/tis.pkl
TisDfCsv = data/preprocessed/tis.csv
JoinedDfPkl = data/input/joined.pkl
JoinedDfCsv = data/input/joined.csv
WindowSplitDict = data/input/window_split.pkl
PredictionsArray = data/output/latest_preds.pkl

[model]
;Seed = 1337
;
VarTarget = Target
; Features = Close
; Features = Open, High, Low, Close, Volume
Features = ICSA, SMA5, SMA10, SMA50, EMA20, stoch5, ADOSC, MACDhist, WILLR, RSI, MOM, ROC, OBV, CCI, Open, High, Low, Close, Volume
; 
HyperParamTuneTrials = 30
; 
Lookback = 64
TrainWindow = 128
ValidationWindow = 32
TestWindow = 64
; 
BatchSizeTrain = 32
BatchSizeValidation = 32
BatchSizeTest = 32
PredictionThreshold = 0.0
; 
Epochs = 50
; 
LSTMUnitsMin = 32
LSTMUnitsMax = 512
; 
HiddenLayersMin = 1
HiddenLayersMax = 3
; 
DropoutRateMin = 0.05
DropoutRateMax = 0.5
; Loss functions -> available problems: {"regression", "classification"}
Problem = regression
LossFunctionRegression = MAPE, MSE
LossMinDeltaMSE = 2.5e-4
LossMinDeltaMape = 50
LossFunctionClassification = binary_crossentropy
LossMinDeltaHinge = 0.03
LossMinDeltaBinaryCrossentropy = 0.00
ActivationFunction = tanh
; 
; LearningRate = 0.05, 0.025, 0.01, 0.005, 0.001
LearningRate = 0.00001
LearningRateDecay = 0.01
Optimizer = Adam, RMSprop, Adadelta
AdamWeightDecay = 0.1
TargetThreshold = 0.001

[evaluation]
TransactionCost = 0.0005
