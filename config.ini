[logger]
LoggerLevel = 20
TensorboardLoggerPath = reports/tblogs

[raw]
IcsaRawDF = data/raw/icsa.csv
CandleRawDF = data/raw/ndx.csv

[prep]
DataPreprocessedDir = data/preprocessed/
DataInputDir = data/input/
DataOutputDir = data/output/
ReportDir = reports/
VisualizationsDir = reports/figures/
ModelParamDir = models/hyperparams/
TunerHistoryDir = models/tuner_history/
FitHistoryDir = models/fit_history/
FitHistoryDir = models/fit_history/
ModelConfigDir = reports/plot-configs/
ModelMetricsDir = reports/performance-metrics/
ExportDir = reports/export/
ExportDir = reports/export/
FFilledIcsaDfPkl = data/preprocessed/icsa_ffilled.pkl
FFilledIcsaDfCsv = data/preprocessed/icsa_ffilled.csv
TisDfPkl = data/preprocessed/tis.pkl
TisDfCsv = data/preprocessed/tis.csv
JoinedDfPkl = data/input/joined.pkl
JoinedDfCsv = data/input/joined.csv
WindowSplitDict = data/input/window_split.pkl
PredictionsArray = data/output/latest_preds.pkl

[model]
;Seed = 1337
;
VarTarget = Target
; Features = Close
; Features = Open, High, Low, Close, Volume
Features = ICSA, SMA5, SMA10, SMA50, EMA20, stoch5, ADOSC, MACDhist, WILLR, RSI, MOM, ROC, OBV, CCI, Open, High, Low, Close, Volume
; 
HyperParamTuneTrials = 30
; 
Lookback = 64
TrainWindow = 1024
ValidationWindow = 256
TestWindow = 128
; 
BatchSizeTrain = 32
BatchSizeValidation = 32
BatchSizeTest = 32
BatchSizeTrain = 32
BatchSizeValidation = 32
BatchSizeTest = 32
PredictionThreshold = 0.0
; 
Epochs = 100
; 
LSTMUnitsMin = 64
LSTMUnitsMax = 512
; 
HiddenLayersMin = 1
HiddenLayersMax = 3
; 
DropoutRateMin = 0.05
DropoutRateMax = 0.5
; Loss functions -> available problems: {regression, classification}
Problem = classification
; Loss functions -> available problems: {regression, classification}
Problem = classification
LossFunctionRegression = MSE
LossFunctionClassification = categorical_crossentropy
LossFunctionClassification = categorical_crossentropy
LossMinDeltaMSE = 2.5e-4
LossMinDeltaMape = 50
LossMinDeltaHinge = 0.03
LossMinDeltaCategoricalCrossEntropy = 0.0001
LossMinDeltaCategoricalCrossEntropy = 0.0001
LossMinDeltaBinaryCrossentropy = 0.00
ActivationFunctionRegression = tanh
ActivationFunctionClassification = softmax
ActivationFunctionRegression = tanh
ActivationFunctionClassification = softmax
; 
LearningRate = 0.05, 0.025, 0.01, 0.005, 0.001, 0.0005, 0.0001
LearningRateDecay = 0.01
Optimizer = Adam, RMSprop
AdamWeightDecay = 0.1
TargetThreshold = 0.0001
TargetThreshold = 0.0001
;
DefaultLearningRate = 0.005
DefaultLossFunction = categorical_crossentropy
DefaultLossFunction = categorical_crossentropy
DefaultOptimizer = Adam
DefaultUnits = 128
DefaultHiddenLayers = 1
DefaultDropout = 0.2

[evaluation]
TransactionCost = 0.0000
